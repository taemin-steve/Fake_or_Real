2023-07-05 15:38:22,957 | train | INFO | Set Logger C:\Users\EHmin\Fake_or_Real\baseline\results\train\20230705_153822
2023-07-05 15:38:23,869 | train | INFO | Load data, train:108201 val:4008
2023-07-05 15:38:26,766 | train | INFO | Initiated early stopper, mode: max, best score: inf, patience: 10
2023-07-05 15:38:26,776 | train | INFO | --Train 0/10
2023-07-05 15:38:42,909 | train | INFO | batch: 0/3381 loss: 2.3810360431671143
2023-07-05 15:40:58,695 | train | INFO | batch: 100/3381 loss: 0.04940447211265564
2023-07-05 15:43:16,813 | train | INFO | batch: 200/3381 loss: 0.06583699584007263
2023-07-05 15:45:36,613 | train | INFO | batch: 300/3381 loss: 0.05254465714097023
2023-07-05 15:47:52,581 | train | INFO | batch: 400/3381 loss: 0.08244705200195312
2023-07-05 15:50:08,749 | train | INFO | batch: 500/3381 loss: 0.09923689067363739
2023-07-05 15:52:27,894 | train | INFO | batch: 600/3381 loss: 0.08035030961036682
2023-07-05 15:54:44,156 | train | INFO | batch: 700/3381 loss: 0.022165236994624138
2023-07-05 15:57:04,906 | train | INFO | batch: 800/3381 loss: 0.19115892052650452
2023-07-05 15:59:21,768 | train | INFO | batch: 900/3381 loss: 0.011936016380786896
2023-07-05 16:01:41,537 | train | INFO | batch: 1000/3381 loss: 0.09822671115398407
2023-07-05 16:04:05,096 | train | INFO | batch: 1100/3381 loss: 0.014550666324794292
2023-07-05 16:06:24,099 | train | INFO | batch: 1200/3381 loss: 0.11712444573640823
2023-07-05 16:08:43,273 | train | INFO | batch: 1300/3381 loss: 0.014380361884832382
2023-07-05 16:11:01,321 | train | INFO | batch: 1400/3381 loss: 0.14700672030448914
2023-07-05 16:13:24,630 | train | INFO | batch: 1500/3381 loss: 0.014183071441948414
2023-07-05 16:15:45,515 | train | INFO | batch: 1600/3381 loss: 0.010817772708833218
2023-07-05 16:18:07,028 | train | INFO | batch: 1700/3381 loss: 0.02323877066373825
2023-07-05 16:20:25,191 | train | INFO | batch: 1800/3381 loss: 0.09332811832427979
2023-07-05 16:22:45,330 | train | INFO | batch: 1900/3381 loss: 0.10008585453033447
2023-07-05 16:25:03,164 | train | INFO | batch: 2000/3381 loss: 0.06943000853061676
2023-07-05 16:27:16,586 | train | INFO | batch: 2100/3381 loss: 0.004499242641031742
2023-07-05 16:29:31,641 | train | INFO | batch: 2200/3381 loss: 0.008773032575845718
2023-07-05 16:31:47,855 | train | INFO | batch: 2300/3381 loss: 0.03383937478065491
2023-07-05 16:34:11,082 | train | INFO | batch: 2400/3381 loss: 0.025823086500167847
2023-07-05 16:36:28,290 | train | INFO | batch: 2500/3381 loss: 0.023188447579741478
2023-07-05 16:38:50,987 | train | INFO | batch: 2600/3381 loss: 0.0733889788389206
2023-07-05 16:41:09,770 | train | INFO | batch: 2700/3381 loss: 0.1145210862159729
2023-07-05 16:43:31,955 | train | INFO | batch: 2800/3381 loss: 0.0056438446044921875
2023-07-05 16:45:49,211 | train | INFO | batch: 2900/3381 loss: 0.07479217648506165
2023-07-05 16:48:07,951 | train | INFO | batch: 3000/3381 loss: 0.016924569383263588
2023-07-05 16:50:23,142 | train | INFO | batch: 3100/3381 loss: 0.0021919377613812685
2023-07-05 16:52:46,823 | train | INFO | batch: 3200/3381 loss: 0.014491891488432884
2023-07-05 16:55:06,957 | train | INFO | batch: 3300/3381 loss: 0.04381241649389267
2023-07-05 16:57:01,974 | train | INFO | --Val 0/10
2023-07-05 16:57:13,320 | train | INFO | batch: 0/125 loss: 0.010886753909289837
2023-07-05 16:59:09,885 | train | INFO | batch: 100/125 loss: 0.01017993874847889
2023-07-05 16:59:36,374 | train | INFO | Write row 0
2023-07-05 16:59:37,872 | train | INFO | Early stopper, counter 0/10, best:0.9895 -> now:0.9895
2023-07-05 16:59:37,872 | train | INFO | Set counter as 0
2023-07-05 16:59:37,872 | train | INFO | Update best score as 0.9895
2023-07-05 16:59:38,111 | train | INFO | Recorder, epoch 0 Model saved: C:\Users\EHmin\Fake_or_Real\baseline\results\train\20230705_153822\model.pt
2023-07-05 16:59:38,111 | train | INFO | --Train 1/10
2023-07-05 16:59:48,747 | train | INFO | batch: 0/3381 loss: 0.04625517502427101
2023-07-05 17:02:11,045 | train | INFO | batch: 100/3381 loss: 0.004854700528085232
2023-07-05 17:04:32,498 | train | INFO | batch: 200/3381 loss: 0.04809795320034027
2023-07-05 17:06:56,631 | train | INFO | batch: 300/3381 loss: 0.007712860591709614
2023-07-05 17:09:21,805 | train | INFO | batch: 400/3381 loss: 0.058086004108190536
2023-07-05 17:11:41,002 | train | INFO | batch: 500/3381 loss: 0.0115747582167387
2023-07-05 17:14:07,866 | train | INFO | batch: 600/3381 loss: 0.05540129542350769
2023-07-05 17:16:27,010 | train | INFO | batch: 700/3381 loss: 0.032639726996421814
2023-07-05 17:18:54,520 | train | INFO | batch: 800/3381 loss: 0.010571269318461418
2023-07-05 17:21:18,364 | train | INFO | batch: 900/3381 loss: 0.013232294470071793
2023-07-05 17:23:45,196 | train | INFO | batch: 1000/3381 loss: 0.10623239725828171
2023-07-05 17:26:07,814 | train | INFO | batch: 1100/3381 loss: 0.012553861364722252
2023-07-05 17:28:24,524 | train | INFO | batch: 1200/3381 loss: 0.13739587366580963
2023-07-05 17:30:40,210 | train | INFO | batch: 1300/3381 loss: 0.007327890954911709
2023-07-05 17:33:02,442 | train | INFO | batch: 1400/3381 loss: 0.0015804648865014315
2023-07-05 17:35:18,861 | train | INFO | batch: 1500/3381 loss: 0.008422411978244781
2023-07-05 17:37:36,432 | train | INFO | batch: 1600/3381 loss: 0.13840018212795258
2023-07-05 17:39:49,204 | train | INFO | batch: 1700/3381 loss: 0.05900706350803375
2023-07-05 17:42:13,308 | train | INFO | batch: 1800/3381 loss: 0.08215422183275223
2023-07-05 17:44:37,538 | train | INFO | batch: 1900/3381 loss: 0.0054471311159431934
2023-07-05 17:46:59,720 | train | INFO | batch: 2000/3381 loss: 0.05292414128780365
2023-07-05 17:49:25,259 | train | INFO | batch: 2100/3381 loss: 0.08350369334220886
2023-07-05 17:51:41,649 | train | INFO | batch: 2200/3381 loss: 0.18302518129348755
2023-07-05 17:54:05,281 | train | INFO | batch: 2300/3381 loss: 0.0519145168364048
2023-07-05 17:56:28,055 | train | INFO | batch: 2400/3381 loss: 0.0039615030400455
2023-07-05 17:58:53,792 | train | INFO | batch: 2500/3381 loss: 0.06811599433422089
2023-07-05 18:01:11,839 | train | INFO | batch: 2600/3381 loss: 0.10901528596878052
2023-07-05 18:03:31,133 | train | INFO | batch: 2700/3381 loss: 0.0021171823609620333
2023-07-05 18:05:44,160 | train | INFO | batch: 2800/3381 loss: 0.021875549107789993
2023-07-05 18:08:05,532 | train | INFO | batch: 2900/3381 loss: 0.0027206805534660816
2023-07-05 18:10:26,847 | train | INFO | batch: 3000/3381 loss: 0.0040082563646137714
2023-07-05 18:12:49,706 | train | INFO | batch: 3100/3381 loss: 0.014702524989843369
2023-07-05 18:15:10,822 | train | INFO | batch: 3200/3381 loss: 0.002894623437896371
2023-07-05 18:17:31,439 | train | INFO | batch: 3300/3381 loss: 0.0776720643043518
2023-07-05 18:19:24,476 | train | INFO | --Val 1/10
2023-07-05 18:19:35,462 | train | INFO | batch: 0/125 loss: 0.0012613404542207718
2023-07-05 18:21:29,665 | train | INFO | batch: 100/125 loss: 0.007642032112926245
2023-07-05 18:21:55,603 | train | INFO | Write row 1
2023-07-05 18:21:56,922 | train | INFO | Early stopper, counter 0/10, best:0.99075 -> now:0.99075
2023-07-05 18:21:56,922 | train | INFO | Set counter as 0
2023-07-05 18:21:56,922 | train | INFO | Update best score as 0.99075
2023-07-05 18:21:57,150 | train | INFO | Recorder, epoch 1 Model saved: C:\Users\EHmin\Fake_or_Real\baseline\results\train\20230705_153822\model.pt
2023-07-05 18:21:57,150 | train | INFO | --Train 2/10
2023-07-05 18:22:07,656 | train | INFO | batch: 0/3381 loss: 0.01497851312160492
2023-07-05 18:24:26,745 | train | INFO | batch: 100/3381 loss: 0.005546107888221741
2023-07-05 18:26:51,711 | train | INFO | batch: 200/3381 loss: 0.04425845295190811
2023-07-05 18:29:12,857 | train | INFO | batch: 300/3381 loss: 0.004109226632863283
2023-07-05 18:31:39,162 | train | INFO | batch: 400/3381 loss: 0.1366477906703949
2023-07-05 18:34:05,545 | train | INFO | batch: 500/3381 loss: 0.005008182022720575
2023-07-05 18:36:30,452 | train | INFO | batch: 600/3381 loss: 0.004213802050799131
2023-07-05 18:38:45,265 | train | INFO | batch: 700/3381 loss: 0.13862989842891693
2023-07-05 18:41:02,692 | train | INFO | batch: 800/3381 loss: 0.004068808164447546
2023-07-05 18:43:18,754 | train | INFO | batch: 900/3381 loss: 0.00306728295981884
2023-07-05 18:45:36,794 | train | INFO | batch: 1000/3381 loss: 0.007153098471462727
2023-07-05 18:48:01,376 | train | INFO | batch: 1100/3381 loss: 0.011059298180043697
2023-07-05 18:50:25,219 | train | INFO | batch: 1200/3381 loss: 0.0038756534922868013
2023-07-05 18:52:46,463 | train | INFO | batch: 1300/3381 loss: 0.004376557189971209
2023-07-05 18:55:05,915 | train | INFO | batch: 1400/3381 loss: 0.16538412868976593
2023-07-05 18:57:25,060 | train | INFO | batch: 1500/3381 loss: 0.0330904982984066
2023-07-05 18:59:44,534 | train | INFO | batch: 1600/3381 loss: 0.03923043608665466
2023-07-05 19:02:02,769 | train | INFO | batch: 1700/3381 loss: 0.002053463365882635
2023-07-05 19:04:18,670 | train | INFO | batch: 1800/3381 loss: 0.048739127814769745
2023-07-05 19:06:37,711 | train | INFO | batch: 1900/3381 loss: 0.04854445159435272
2023-07-05 19:08:59,169 | train | INFO | batch: 2000/3381 loss: 0.1327904462814331
2023-07-05 19:11:23,554 | train | INFO | batch: 2100/3381 loss: 0.0063153477385640144
2023-07-05 19:13:45,996 | train | INFO | batch: 2200/3381 loss: 0.0453389436006546
2023-07-05 19:16:03,941 | train | INFO | batch: 2300/3381 loss: 0.010233339853584766
2023-07-05 19:18:22,853 | train | INFO | batch: 2400/3381 loss: 0.00034028745722025633
2023-07-05 19:20:44,134 | train | INFO | batch: 2500/3381 loss: 0.015097392722964287
2023-07-05 19:23:00,657 | train | INFO | batch: 2600/3381 loss: 0.012427772395312786
2023-07-05 19:25:25,311 | train | INFO | batch: 2700/3381 loss: 0.002016142476350069
2023-07-05 19:27:49,837 | train | INFO | batch: 2800/3381 loss: 0.008584918454289436
2023-07-05 19:30:15,224 | train | INFO | batch: 2900/3381 loss: 0.1141151487827301
2023-07-05 19:32:31,761 | train | INFO | batch: 3000/3381 loss: 0.007627499755471945
2023-07-05 19:34:54,260 | train | INFO | batch: 3100/3381 loss: 0.0026968950405716896
2023-07-05 19:37:18,076 | train | INFO | batch: 3200/3381 loss: 0.06341017782688141
2023-07-05 19:39:43,935 | train | INFO | batch: 3300/3381 loss: 0.019801605492830276
2023-07-05 19:41:46,297 | train | INFO | --Val 2/10
2023-07-05 19:41:57,598 | train | INFO | batch: 0/125 loss: 0.0013772991951555014
2023-07-05 19:43:53,966 | train | INFO | batch: 100/125 loss: 0.07836169004440308
2023-07-05 19:44:19,860 | train | INFO | Write row 2
2023-07-05 19:44:21,295 | train | INFO | Early stopper, counter 1/10, best:0.99075 -> now:0.98925
2023-07-05 19:44:21,295 | train | INFO | --Train 3/10
2023-07-05 19:44:30,967 | train | INFO | batch: 0/3381 loss: 0.016217859461903572
2023-07-05 19:46:50,602 | train | INFO | batch: 100/3381 loss: 0.02239537611603737
2023-07-05 19:49:10,959 | train | INFO | batch: 200/3381 loss: 0.02976931259036064
2023-07-05 19:51:31,824 | train | INFO | batch: 300/3381 loss: 0.003772052936255932
2023-07-05 19:53:57,736 | train | INFO | batch: 400/3381 loss: 0.002718338742852211
2023-07-05 19:56:15,417 | train | INFO | batch: 500/3381 loss: 0.036679599434137344
2023-07-05 19:58:44,508 | train | INFO | batch: 600/3381 loss: 0.010478334501385689
2023-07-05 20:01:15,008 | train | INFO | batch: 700/3381 loss: 0.026340976357460022
2023-07-05 20:03:30,876 | train | INFO | batch: 800/3381 loss: 0.0015108359511941671
2023-07-05 20:05:51,578 | train | INFO | batch: 900/3381 loss: 0.006375719793140888
2023-07-05 20:08:13,287 | train | INFO | batch: 1000/3381 loss: 0.002153994981199503
2023-07-05 20:10:36,611 | train | INFO | batch: 1100/3381 loss: 0.009263208135962486
2023-07-05 20:12:58,390 | train | INFO | batch: 1200/3381 loss: 0.016120804473757744
2023-07-05 20:15:17,717 | train | INFO | batch: 1300/3381 loss: 0.026286350563168526
2023-07-05 20:17:43,140 | train | INFO | batch: 1400/3381 loss: 0.0032299417071044445
2023-07-05 20:20:03,959 | train | INFO | batch: 1500/3381 loss: 0.002011327538639307
2023-07-05 20:22:23,590 | train | INFO | batch: 1600/3381 loss: 0.22891035676002502
2023-07-05 20:24:46,426 | train | INFO | batch: 1700/3381 loss: 0.004467139020562172
2023-07-05 20:27:09,672 | train | INFO | batch: 1800/3381 loss: 0.005744893569499254
2023-07-05 20:29:30,267 | train | INFO | batch: 1900/3381 loss: 0.11144256591796875
2023-07-05 20:31:55,364 | train | INFO | batch: 2000/3381 loss: 0.059809718281030655
2023-07-05 20:34:17,610 | train | INFO | batch: 2100/3381 loss: 0.0026013501919806004
2023-07-05 20:36:48,874 | train | INFO | batch: 2200/3381 loss: 0.010143506340682507
2023-07-05 20:39:07,124 | train | INFO | batch: 2300/3381 loss: 0.05370410531759262
2023-07-05 20:41:32,257 | train | INFO | batch: 2400/3381 loss: 0.07957957684993744
2023-07-05 20:43:45,459 | train | INFO | batch: 2500/3381 loss: 0.012567154131829739
2023-07-05 20:46:04,112 | train | INFO | batch: 2600/3381 loss: 0.0033219479955732822
2023-07-05 20:48:23,349 | train | INFO | batch: 2700/3381 loss: 0.17320244014263153
2023-07-05 20:50:44,825 | train | INFO | batch: 2800/3381 loss: 0.015101833269000053
2023-07-05 20:53:09,275 | train | INFO | batch: 2900/3381 loss: 0.018963152542710304
2023-07-05 20:55:25,532 | train | INFO | batch: 3000/3381 loss: 0.03406813368201256
2023-07-05 20:57:52,031 | train | INFO | batch: 3100/3381 loss: 0.10103917866945267
2023-07-05 21:00:13,708 | train | INFO | batch: 3200/3381 loss: 0.0037953995633870363
2023-07-05 21:02:42,307 | train | INFO | batch: 3300/3381 loss: 0.0033099716529250145
2023-07-05 21:04:33,249 | train | INFO | --Val 3/10
2023-07-05 21:04:44,482 | train | INFO | batch: 0/125 loss: 0.03880403935909271
2023-07-05 21:06:40,142 | train | INFO | batch: 100/125 loss: 0.00296994112432003
2023-07-05 21:07:06,637 | train | INFO | Write row 3
2023-07-05 21:07:07,964 | train | INFO | Early stopper, counter 2/10, best:0.99075 -> now:0.99
2023-07-05 21:07:07,964 | train | INFO | --Train 4/10
2023-07-05 21:07:17,690 | train | INFO | batch: 0/3381 loss: 0.053271252661943436
2023-07-05 21:09:37,389 | train | INFO | batch: 100/3381 loss: 0.04669039323925972
2023-07-05 21:12:01,759 | train | INFO | batch: 200/3381 loss: 0.015301271341741085
2023-07-05 21:14:24,636 | train | INFO | batch: 300/3381 loss: 0.0010954634053632617
2023-07-05 21:16:44,076 | train | INFO | batch: 400/3381 loss: 0.004377164877951145
2023-07-05 21:19:08,582 | train | INFO | batch: 500/3381 loss: 0.0017516296356916428
2023-07-05 21:21:29,845 | train | INFO | batch: 600/3381 loss: 0.008659226819872856
2023-07-05 21:23:54,894 | train | INFO | batch: 700/3381 loss: 0.0008089686743915081
2023-07-05 21:26:11,462 | train | INFO | batch: 800/3381 loss: 0.02157539688050747
2023-07-05 21:28:31,015 | train | INFO | batch: 900/3381 loss: 0.011676231399178505
2023-07-05 21:30:44,619 | train | INFO | batch: 1000/3381 loss: 0.01187035534530878
2023-07-05 21:33:07,642 | train | INFO | batch: 1100/3381 loss: 0.001172544900327921
2023-07-05 21:35:46,983 | train | INFO | batch: 1200/3381 loss: 0.01095718052238226
2023-07-05 21:38:24,724 | train | INFO | batch: 1300/3381 loss: 0.06518875062465668
2023-07-05 21:40:41,610 | train | INFO | batch: 1400/3381 loss: 0.019854668527841568
2023-07-05 21:43:05,002 | train | INFO | batch: 1500/3381 loss: 0.14227165281772614
2023-07-05 21:45:28,915 | train | INFO | batch: 1600/3381 loss: 0.005935369525104761
2023-07-05 21:47:45,296 | train | INFO | batch: 1700/3381 loss: 0.004614177159965038
2023-07-05 21:50:06,959 | train | INFO | batch: 1800/3381 loss: 0.00572806503623724
2023-07-05 21:52:25,018 | train | INFO | batch: 1900/3381 loss: 0.007006030064076185
2023-07-05 21:54:39,980 | train | INFO | batch: 2000/3381 loss: 0.024278445169329643
2023-07-05 21:56:57,651 | train | INFO | batch: 2100/3381 loss: 0.0061790598556399345
2023-07-05 21:59:19,600 | train | INFO | batch: 2200/3381 loss: 0.031876225024461746
2023-07-05 22:01:43,488 | train | INFO | batch: 2300/3381 loss: 0.01774413138628006
2023-07-05 22:04:06,690 | train | INFO | batch: 2400/3381 loss: 0.01568755879998207
2023-07-05 22:06:35,274 | train | INFO | batch: 2500/3381 loss: 0.009767618030309677
2023-07-05 22:08:56,767 | train | INFO | batch: 2600/3381 loss: 0.007982446812093258
2023-07-05 22:11:19,015 | train | INFO | batch: 2700/3381 loss: 0.002424286212772131
2023-07-05 22:13:42,817 | train | INFO | batch: 2800/3381 loss: 0.0010371169773861766
2023-07-05 22:16:03,151 | train | INFO | batch: 2900/3381 loss: 0.011129197664558887
2023-07-05 22:18:16,222 | train | INFO | batch: 3000/3381 loss: 0.0069970074109733105
2023-07-05 22:20:34,964 | train | INFO | batch: 3100/3381 loss: 0.003690008306875825
2023-07-05 22:22:57,964 | train | INFO | batch: 3200/3381 loss: 0.01756429299712181
2023-07-05 22:25:23,801 | train | INFO | batch: 3300/3381 loss: 0.0020229551009833813
2023-07-05 22:27:21,563 | train | INFO | --Val 4/10
2023-07-05 22:27:33,707 | train | INFO | batch: 0/125 loss: 0.00349669111892581
2023-07-05 22:29:27,229 | train | INFO | batch: 100/125 loss: 0.009670206345617771
2023-07-05 22:29:53,331 | train | INFO | Write row 4
2023-07-05 22:29:54,712 | train | INFO | Early stopper, counter 3/10, best:0.99075 -> now:0.9905
2023-07-05 22:29:54,712 | train | INFO | --Train 5/10
2023-07-05 22:30:04,950 | train | INFO | batch: 0/3381 loss: 0.004712644964456558
2023-07-05 22:32:30,906 | train | INFO | batch: 100/3381 loss: 0.005181917920708656
2023-07-05 22:34:51,520 | train | INFO | batch: 200/3381 loss: 0.004514215514063835
2023-07-05 22:37:11,112 | train | INFO | batch: 300/3381 loss: 0.022007454186677933
2023-07-05 22:39:29,432 | train | INFO | batch: 400/3381 loss: 0.13243751227855682
2023-07-05 22:41:55,828 | train | INFO | batch: 500/3381 loss: 0.028131451457738876
2023-07-05 22:44:19,343 | train | INFO | batch: 600/3381 loss: 0.03128181770443916
2023-07-05 22:46:41,153 | train | INFO | batch: 700/3381 loss: 0.002023809589445591
2023-07-05 22:49:07,342 | train | INFO | batch: 800/3381 loss: 0.0673375204205513
2023-07-05 22:51:26,465 | train | INFO | batch: 900/3381 loss: 0.029323210939764977
2023-07-05 22:53:52,238 | train | INFO | batch: 1000/3381 loss: 0.004972337279468775
2023-07-05 22:56:14,498 | train | INFO | batch: 1100/3381 loss: 0.01208897028118372
2023-07-05 22:58:36,177 | train | INFO | batch: 1200/3381 loss: 0.0001502435770817101
2023-07-05 23:00:58,504 | train | INFO | batch: 1300/3381 loss: 0.0052618058398365974
2023-07-05 23:03:22,475 | train | INFO | batch: 1400/3381 loss: 0.019532103091478348
2023-07-05 23:05:35,960 | train | INFO | batch: 1500/3381 loss: 0.0024600208271294832
2023-07-05 23:08:02,713 | train | INFO | batch: 1600/3381 loss: 0.02752826362848282
2023-07-05 23:10:27,903 | train | INFO | batch: 1700/3381 loss: 0.003408667165786028
2023-07-05 23:12:48,903 | train | INFO | batch: 1800/3381 loss: 0.0567326545715332
2023-07-05 23:15:12,187 | train | INFO | batch: 1900/3381 loss: 0.0007034033187665045
2023-07-05 23:17:32,467 | train | INFO | batch: 2000/3381 loss: 0.028501946479082108
2023-07-05 23:19:52,167 | train | INFO | batch: 2100/3381 loss: 0.06420618295669556
2023-07-05 23:22:12,414 | train | INFO | batch: 2200/3381 loss: 0.003548718523234129
2023-07-05 23:24:27,459 | train | INFO | batch: 2300/3381 loss: 0.022372635081410408
2023-07-05 23:26:50,359 | train | INFO | batch: 2400/3381 loss: 0.10254610329866409
2023-07-05 23:29:14,013 | train | INFO | batch: 2500/3381 loss: 0.06326062977313995
2023-07-05 23:31:31,422 | train | INFO | batch: 2600/3381 loss: 0.01448672916740179
2023-07-05 23:33:58,584 | train | INFO | batch: 2700/3381 loss: 0.0024913621600717306
2023-07-05 23:36:22,069 | train | INFO | batch: 2800/3381 loss: 0.09655525535345078
2023-07-05 23:38:42,085 | train | INFO | batch: 2900/3381 loss: 0.00121864746324718
2023-07-05 23:41:04,022 | train | INFO | batch: 3000/3381 loss: 0.02071963995695114
2023-07-05 23:43:21,314 | train | INFO | batch: 3100/3381 loss: 0.021633313968777657
2023-07-05 23:45:42,701 | train | INFO | batch: 3200/3381 loss: 0.0016525816172361374
2023-07-05 23:48:01,331 | train | INFO | batch: 3300/3381 loss: 0.019293060526251793
2023-07-05 23:49:52,787 | train | INFO | --Val 5/10
2023-07-05 23:50:03,817 | train | INFO | batch: 0/125 loss: 0.008373570628464222
2023-07-05 23:51:57,763 | train | INFO | batch: 100/125 loss: 0.00842976849526167
2023-07-05 23:52:24,163 | train | INFO | Write row 5
2023-07-05 23:52:25,683 | train | INFO | Early stopper, counter 0/10, best:0.992 -> now:0.992
2023-07-05 23:52:25,683 | train | INFO | Set counter as 0
2023-07-05 23:52:25,683 | train | INFO | Update best score as 0.992
2023-07-05 23:52:25,904 | train | INFO | Recorder, epoch 5 Model saved: C:\Users\EHmin\Fake_or_Real\baseline\results\train\20230705_153822\model.pt
2023-07-05 23:52:25,905 | train | INFO | --Train 6/10
2023-07-05 23:52:35,829 | train | INFO | batch: 0/3381 loss: 0.0187574103474617
2023-07-05 23:55:05,308 | train | INFO | batch: 100/3381 loss: 0.006197643466293812
2023-07-05 23:57:26,624 | train | INFO | batch: 200/3381 loss: 0.0010119210928678513
2023-07-05 23:59:44,434 | train | INFO | batch: 300/3381 loss: 0.0003814909723587334
2023-07-06 00:02:00,878 | train | INFO | batch: 400/3381 loss: 0.00026582935242913663
2023-07-06 00:04:28,155 | train | INFO | batch: 500/3381 loss: 0.005746547132730484
2023-07-06 00:06:49,666 | train | INFO | batch: 600/3381 loss: 0.0005759756895713508
2023-07-06 00:09:13,650 | train | INFO | batch: 700/3381 loss: 0.008972899056971073
2023-07-06 00:11:35,008 | train | INFO | batch: 800/3381 loss: 0.0010963636450469494
2023-07-06 00:13:48,520 | train | INFO | batch: 900/3381 loss: 0.0027600680477917194
2023-07-06 00:16:12,800 | train | INFO | batch: 1000/3381 loss: 0.001131515484303236
2023-07-06 00:18:38,216 | train | INFO | batch: 1100/3381 loss: 0.03570184111595154
2023-07-06 00:20:59,591 | train | INFO | batch: 1200/3381 loss: 0.0006634565070271492
2023-07-06 00:23:14,836 | train | INFO | batch: 1300/3381 loss: 0.015060129575431347
2023-07-06 00:25:32,775 | train | INFO | batch: 1400/3381 loss: 0.0014194197719916701
2023-07-06 00:27:59,917 | train | INFO | batch: 1500/3381 loss: 0.0010975226759910583
2023-07-06 00:30:18,806 | train | INFO | batch: 1600/3381 loss: 0.0136948237195611
2023-07-06 00:32:38,348 | train | INFO | batch: 1700/3381 loss: 0.005508956499397755
2023-07-06 00:35:04,231 | train | INFO | batch: 1800/3381 loss: 0.07268711924552917
2023-07-06 00:37:25,157 | train | INFO | batch: 1900/3381 loss: 0.042182695120573044
2023-07-06 00:39:58,834 | train | INFO | batch: 2000/3381 loss: 0.0076742153614759445
2023-07-06 00:42:21,141 | train | INFO | batch: 2100/3381 loss: 0.011102486401796341
2023-07-06 00:44:38,246 | train | INFO | batch: 2200/3381 loss: 0.04941759258508682
2023-07-06 00:47:05,456 | train | INFO | batch: 2300/3381 loss: 0.02980184368789196
2023-07-06 00:49:31,961 | train | INFO | batch: 2400/3381 loss: 0.019576657563447952
2023-07-06 00:51:43,171 | train | INFO | batch: 2500/3381 loss: 0.00022271875059232116
2023-07-06 00:54:03,786 | train | INFO | batch: 2600/3381 loss: 0.00206828024238348
2023-07-06 00:56:28,857 | train | INFO | batch: 2700/3381 loss: 0.0031844917684793472
2023-07-06 00:58:52,444 | train | INFO | batch: 2800/3381 loss: 0.0298989936709404
2023-07-06 01:01:10,943 | train | INFO | batch: 2900/3381 loss: 0.0024741673842072487
2023-07-06 01:03:34,142 | train | INFO | batch: 3000/3381 loss: 0.0038876617327332497
2023-07-06 01:05:56,360 | train | INFO | batch: 3100/3381 loss: 0.0010161492973566055
2023-07-06 01:08:14,174 | train | INFO | batch: 3200/3381 loss: 0.03262368217110634
2023-07-06 01:10:42,773 | train | INFO | batch: 3300/3381 loss: 0.008606575429439545
2023-07-06 01:12:34,466 | train | INFO | --Val 6/10
2023-07-06 01:12:45,956 | train | INFO | batch: 0/125 loss: 0.00585890281945467
2023-07-06 01:14:40,595 | train | INFO | batch: 100/125 loss: 0.02351270243525505
2023-07-06 01:15:06,554 | train | INFO | Write row 6
2023-07-06 01:15:08,085 | train | INFO | Early stopper, counter 0/10, best:0.993 -> now:0.993
2023-07-06 01:15:08,085 | train | INFO | Set counter as 0
2023-07-06 01:15:08,085 | train | INFO | Update best score as 0.993
2023-07-06 01:15:08,298 | train | INFO | Recorder, epoch 6 Model saved: C:\Users\EHmin\Fake_or_Real\baseline\results\train\20230705_153822\model.pt
2023-07-06 01:15:08,298 | train | INFO | --Train 7/10
2023-07-06 01:15:17,990 | train | INFO | batch: 0/3381 loss: 0.02728753723204136
2023-07-06 01:17:37,801 | train | INFO | batch: 100/3381 loss: 0.03620925173163414
2023-07-06 01:20:06,784 | train | INFO | batch: 200/3381 loss: 0.014104575850069523
2023-07-06 01:22:24,852 | train | INFO | batch: 300/3381 loss: 0.1488671600818634
2023-07-06 01:24:50,421 | train | INFO | batch: 400/3381 loss: 0.0127407880499959
2023-07-06 01:27:14,153 | train | INFO | batch: 500/3381 loss: 0.010273775085806847
2023-07-06 01:29:32,889 | train | INFO | batch: 600/3381 loss: 0.012134062126278877
2023-07-06 01:31:48,422 | train | INFO | batch: 700/3381 loss: 0.0018685741815716028
2023-07-06 01:34:12,311 | train | INFO | batch: 800/3381 loss: 0.0002580603177193552
2023-07-06 01:36:36,419 | train | INFO | batch: 900/3381 loss: 0.0020242275204509497
2023-07-06 01:38:56,289 | train | INFO | batch: 1000/3381 loss: 0.001824342180043459
2023-07-06 01:41:17,419 | train | INFO | batch: 1100/3381 loss: 0.0353206992149353
2023-07-06 01:43:41,910 | train | INFO | batch: 1200/3381 loss: 0.002824785653501749
2023-07-06 01:46:05,666 | train | INFO | batch: 1300/3381 loss: 0.001069984631612897
2023-07-06 01:48:26,930 | train | INFO | batch: 1400/3381 loss: 0.09186920523643494
2023-07-06 01:50:53,125 | train | INFO | batch: 1500/3381 loss: 0.03189439699053764
2023-07-06 01:53:15,207 | train | INFO | batch: 1600/3381 loss: 0.0675535500049591
2023-07-06 01:55:38,398 | train | INFO | batch: 1700/3381 loss: 0.007947148755192757
2023-07-06 01:57:59,209 | train | INFO | batch: 1800/3381 loss: 0.0005228047957643867
2023-07-06 02:00:26,038 | train | INFO | batch: 1900/3381 loss: 0.007459675893187523
2023-07-06 02:02:48,334 | train | INFO | batch: 2000/3381 loss: 0.0007688674959354103
2023-07-06 02:05:10,618 | train | INFO | batch: 2100/3381 loss: 0.023013534024357796
2023-07-06 02:07:28,135 | train | INFO | batch: 2200/3381 loss: 0.0006259215879254043
2023-07-06 02:09:54,745 | train | INFO | batch: 2300/3381 loss: 0.0009076151764020324
2023-07-06 02:12:17,971 | train | INFO | batch: 2400/3381 loss: 0.012113921344280243
2023-07-06 02:14:37,236 | train | INFO | batch: 2500/3381 loss: 0.061396267265081406
2023-07-06 02:17:02,159 | train | INFO | batch: 2600/3381 loss: 0.008943246677517891
2023-07-06 02:19:23,766 | train | INFO | batch: 2700/3381 loss: 0.08721090853214264
2023-07-06 02:21:44,457 | train | INFO | batch: 2800/3381 loss: 0.006020968779921532
2023-07-06 02:24:02,177 | train | INFO | batch: 2900/3381 loss: 0.002877716673538089
2023-07-06 02:26:22,246 | train | INFO | batch: 3000/3381 loss: 0.00036410646862350404
2023-07-06 02:28:43,018 | train | INFO | batch: 3100/3381 loss: 0.0006300269160419703
2023-07-06 02:30:59,782 | train | INFO | batch: 3200/3381 loss: 0.00037912241532467306
2023-07-06 02:33:26,859 | train | INFO | batch: 3300/3381 loss: 0.0014914153143763542
2023-07-06 02:35:21,059 | train | INFO | --Val 7/10
2023-07-06 02:35:32,466 | train | INFO | batch: 0/125 loss: 0.009333116002380848
2023-07-06 02:37:27,265 | train | INFO | batch: 100/125 loss: 0.05545378848910332
2023-07-06 02:37:53,106 | train | INFO | Write row 7
2023-07-06 02:37:54,717 | train | INFO | Early stopper, counter 1/10, best:0.993 -> now:0.9915
2023-07-06 02:37:54,717 | train | INFO | --Train 8/10
2023-07-06 02:38:04,106 | train | INFO | batch: 0/3381 loss: 0.010231307707726955
2023-07-06 02:40:24,845 | train | INFO | batch: 100/3381 loss: 0.06723428517580032
2023-07-06 02:42:55,459 | train | INFO | batch: 200/3381 loss: 0.08413282036781311
2023-07-06 02:45:15,278 | train | INFO | batch: 300/3381 loss: 0.003777461126446724
2023-07-06 02:47:34,837 | train | INFO | batch: 400/3381 loss: 0.01959899440407753
2023-07-06 02:50:01,174 | train | INFO | batch: 500/3381 loss: 0.00022647209698334336
2023-07-06 02:52:20,340 | train | INFO | batch: 600/3381 loss: 0.029544800519943237
2023-07-06 02:54:41,939 | train | INFO | batch: 700/3381 loss: 0.23704901337623596
2023-07-06 02:56:57,297 | train | INFO | batch: 800/3381 loss: 0.00032429449493065476
2023-07-06 02:59:24,226 | train | INFO | batch: 900/3381 loss: 0.001913607120513916
2023-07-06 03:01:47,498 | train | INFO | batch: 1000/3381 loss: 0.002205129247158766
2023-07-06 03:04:08,829 | train | INFO | batch: 1100/3381 loss: 0.0056886677630245686
2023-07-06 03:06:29,007 | train | INFO | batch: 1200/3381 loss: 0.008543065749108791
2023-07-06 03:08:52,276 | train | INFO | batch: 1300/3381 loss: 0.0008167211199179292
2023-07-06 03:11:08,602 | train | INFO | batch: 1400/3381 loss: 0.06944525986909866
2023-07-06 03:13:23,753 | train | INFO | batch: 1500/3381 loss: 0.0015552786644548178
2023-07-06 03:15:50,133 | train | INFO | batch: 1600/3381 loss: 0.0038328433874994516
2023-07-06 03:18:10,441 | train | INFO | batch: 1700/3381 loss: 0.047376446425914764
2023-07-06 03:20:31,443 | train | INFO | batch: 1800/3381 loss: 0.001740733627229929
2023-07-06 03:22:52,355 | train | INFO | batch: 1900/3381 loss: 0.007321537472307682
2023-07-06 03:25:15,681 | train | INFO | batch: 2000/3381 loss: 0.0018217582255601883
2023-07-06 03:27:35,198 | train | INFO | batch: 2100/3381 loss: 0.00030164042254909873
2023-07-06 03:30:02,721 | train | INFO | batch: 2200/3381 loss: 0.002655338030308485
2023-07-06 03:32:21,172 | train | INFO | batch: 2300/3381 loss: 0.0005221491446718574
2023-07-06 03:34:38,191 | train | INFO | batch: 2400/3381 loss: 0.003591796848922968
2023-07-06 03:36:56,471 | train | INFO | batch: 2500/3381 loss: 0.05856001377105713
2023-07-06 03:39:16,742 | train | INFO | batch: 2600/3381 loss: 0.08561182767152786
2023-07-06 03:41:42,738 | train | INFO | batch: 2700/3381 loss: 0.005635908339172602
2023-07-06 03:44:04,574 | train | INFO | batch: 2800/3381 loss: 0.06486891210079193
2023-07-06 03:46:28,077 | train | INFO | batch: 2900/3381 loss: 0.0006241508526727557
2023-07-06 03:48:50,648 | train | INFO | batch: 3000/3381 loss: 0.0004962977836839855
2023-07-06 03:51:11,783 | train | INFO | batch: 3100/3381 loss: 0.004915973637253046
2023-07-06 03:53:38,825 | train | INFO | batch: 3200/3381 loss: 0.0068956161849200726
2023-07-06 03:56:01,684 | train | INFO | batch: 3300/3381 loss: 0.0006886541377753019
2023-07-06 03:57:58,408 | train | INFO | --Val 8/10
2023-07-06 03:58:09,606 | train | INFO | batch: 0/125 loss: 0.0012302468530833721
2023-07-06 04:00:04,313 | train | INFO | batch: 100/125 loss: 0.015932338312268257
2023-07-06 04:00:30,361 | train | INFO | Write row 8
2023-07-06 04:00:31,948 | train | INFO | Early stopper, counter 2/10, best:0.993 -> now:0.99025
2023-07-06 04:00:31,948 | train | INFO | --Train 9/10
2023-07-06 04:00:42,624 | train | INFO | batch: 0/3381 loss: 0.019655194133520126
2023-07-06 04:03:09,237 | train | INFO | batch: 100/3381 loss: 0.00048740487545728683
2023-07-06 04:05:35,620 | train | INFO | batch: 200/3381 loss: 0.01748505048453808
2023-07-06 04:07:50,436 | train | INFO | batch: 300/3381 loss: 0.0002983414160553366
2023-07-06 04:10:12,906 | train | INFO | batch: 400/3381 loss: 0.0007257054676301777
2023-07-06 04:12:40,744 | train | INFO | batch: 500/3381 loss: 0.018660370260477066
2023-07-06 04:14:59,044 | train | INFO | batch: 600/3381 loss: 0.15550316870212555
2023-07-06 04:17:24,688 | train | INFO | batch: 700/3381 loss: 0.00597041891887784
2023-07-06 04:19:42,182 | train | INFO | batch: 800/3381 loss: 0.08739632368087769
2023-07-06 04:22:00,866 | train | INFO | batch: 900/3381 loss: 0.010288432240486145
2023-07-06 04:24:21,573 | train | INFO | batch: 1000/3381 loss: 0.0019074940355494618
2023-07-06 04:26:43,308 | train | INFO | batch: 1100/3381 loss: 0.005837258417159319
2023-07-06 04:29:07,264 | train | INFO | batch: 1200/3381 loss: 0.001004763413220644
2023-07-06 04:31:34,717 | train | INFO | batch: 1300/3381 loss: 0.0001385367795592174
2023-07-06 04:33:55,170 | train | INFO | batch: 1400/3381 loss: 0.00228025927208364
2023-07-06 04:36:13,100 | train | INFO | batch: 1500/3381 loss: 0.0553901381790638
2023-07-06 04:38:38,248 | train | INFO | batch: 1600/3381 loss: 0.04058348760008812
2023-07-06 04:41:00,754 | train | INFO | batch: 1700/3381 loss: 0.03553289547562599
2023-07-06 04:43:27,319 | train | INFO | batch: 1800/3381 loss: 0.0013964527752250433
2023-07-06 04:45:52,224 | train | INFO | batch: 1900/3381 loss: 0.0016320515424013138
2023-07-06 04:48:19,111 | train | INFO | batch: 2000/3381 loss: 0.0024303263053297997
2023-07-06 04:50:43,311 | train | INFO | batch: 2100/3381 loss: 0.004209831822663546
2023-07-06 04:53:08,202 | train | INFO | batch: 2200/3381 loss: 0.014585347846150398
2023-07-06 04:55:32,168 | train | INFO | batch: 2300/3381 loss: 0.013990100473165512
2023-07-06 04:57:54,469 | train | INFO | batch: 2400/3381 loss: 0.0010775122791528702
2023-07-06 05:00:18,359 | train | INFO | batch: 2500/3381 loss: 0.014277608133852482
2023-07-06 05:02:41,828 | train | INFO | batch: 2600/3381 loss: 0.003965453710407019
2023-07-06 05:04:59,096 | train | INFO | batch: 2700/3381 loss: 0.0028919600881636143
2023-07-06 05:07:31,025 | train | INFO | batch: 2800/3381 loss: 0.0037131791468709707
2023-07-06 05:09:52,819 | train | INFO | batch: 2900/3381 loss: 0.0033790976740419865
2023-07-06 05:12:15,848 | train | INFO | batch: 3000/3381 loss: 0.13641393184661865
2023-07-06 05:14:39,968 | train | INFO | batch: 3100/3381 loss: 0.020758338272571564
2023-07-06 05:16:59,740 | train | INFO | batch: 3200/3381 loss: 0.012501122429966927
2023-07-06 05:19:22,205 | train | INFO | batch: 3300/3381 loss: 0.004263016860932112
2023-07-06 05:21:15,480 | train | INFO | --Val 9/10
2023-07-06 05:21:26,559 | train | INFO | batch: 0/125 loss: 0.0002628080255817622
2023-07-06 05:23:21,934 | train | INFO | batch: 100/125 loss: 0.00681831082329154
2023-07-06 05:23:48,022 | train | INFO | Write row 9
2023-07-06 05:23:49,574 | train | INFO | Early stopper, counter 3/10, best:0.993 -> now:0.99025
2023-07-06 05:23:49,809 | train | INFO | Recorder, epoch 9 Model saved: C:\Users\EHmin\Fake_or_Real\baseline\results\train\20230705_153822\model.pt
